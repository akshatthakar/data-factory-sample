{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "moderndwhdatafactory"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/RestResource1')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "RestService_dumy",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": "/transacts?from-date=2015-12-01&to-date=2015-12-02"
				},
				"schema": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline_restconnect')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Fetch Token",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"url": "https://login.microsoftonline.com/124d38e1-fd5b-4382-87c5-0323f8b79b62/oauth2/token",
							"method": "POST",
							"headers": {
								"Content-type": "application/x-www-form-urlencoded"
							},
							"body": "grant_type=client_credentials&client_secret=Np2APxLvWiUK_pszRHSrby0g1HHv95_H~k&client_id=http://demodwhaccount&resource=https://management.azure.com\n"
						}
					},
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Fetch Token",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET"
							},
							"sink": {
								"type": "JsonSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "JsonWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "RestResource1",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "Json1",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"annotations": [],
				"lastPublishTime": "2021-06-21T14:21:39Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/RestResource1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowcompartment')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "IntermediateCSV",
								"type": "DatasetReference"
							},
							"name": "CSVSource"
						},
						{
							"dataset": {
								"referenceName": "AzureSynapseAnalyticsGroup",
								"type": "DatasetReference"
							},
							"name": "dwhdb"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSynapseAnalyticsGroup",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "createHash"
						},
						{
							"name": "Exists1"
						},
						{
							"name": "Lookup1"
						},
						{
							"name": "SetAttrributes"
						},
						{
							"name": "Aggregate1"
						},
						{
							"name": "CreateHashNewData"
						},
						{
							"name": "AlterRow1"
						}
					],
					"script": "source(output(\n\t\tStore_Code as integer,\n\t\tStore_Name as string,\n\t\tCOMPANY as string,\n\t\tCompartment as string,\n\t\tSubCompartment as string,\n\t\tTYPE as string,\n\t\tnick_name as string,\n\t\tprod_code as string,\n\t\tNetSold_Qty as short,\n\t\tCost as string,\n\t\tRetail_Price as string,\n\t\tUnit_Price_Sold as string,\n\t\tFinalPrice as boolean,\n\t\tCONCESSION_ID as integer,\n\t\tCONCESSION_Code as string,\n\t\tNew_Price_After_Discount as string,\n\t\tCONCESSION_Description as string,\n\t\tAmount_Discount as string,\n\t\tPercent_Discount as double,\n\t\tNetSold_Amount as string,\n\t\tTAX_RATE as double,\n\t\tTAX_AMOUNT1 as double,\n\t\tTAX_AMOUNT2 as double,\n\t\temp_code as string,\n\t\tEmp_Name as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> CSVSource\nsource(output(\n\t\tGRP_ID as integer,\n\t\tGRP_NAME as string,\n\t\tSECTION as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> dwhdb\ndwhdb derive(dimhash = sha1(GRP_NAME+ SECTION)) ~> createHash\nCreateHashNewData, createHash exists(newdatahash == dimhash,\n\tnegate:true,\n\tbroadcast: 'auto')~> Exists1\nExists1, dwhdb lookup(toString(Compartment) == GRP_NAME,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> Lookup1\nLookup1 derive(GRP_NAME = Compartment,\n\t\tSECTION = SubCompartment,\n\t\t{_inserted_dt} = iif(isNull(GRP_ID) ,  currentTimestamp(), {_inserted_dt}),\n\t\t{_updated_dt} = currentTimestamp()) ~> SetAttrributes\nSetAttrributes aggregate(groupBy(SECTION,\n\t\tGRP_NAME,\n\t\tGRP_ID,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}),\n\tcount = count(SECTION)) ~> Aggregate1\nCSVSource derive(newdatahash = sha1(Compartment + SubCompartment)) ~> CreateHashNewData\nAggregate1 alterRow(insertIf(isNull(GRP_ID)),\n\tupdateIf(not(isNull(GRP_ID)))) ~> AlterRow1\nAlterRow1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tGRP_ID as integer,\n\t\tGRP_NAME as string,\n\t\tSECTION as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:true,\n\tupsertable:false,\n\tkeys:['GRP_NAME'],\n\tformat: 'table',\n\tstaged: true,\n\tallowCopyCommand: true,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError',\n\tmapColumn(\n\t\tSECTION,\n\t\tGRP_NAME,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowconcession')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "IntermediateCSV",
								"type": "DatasetReference"
							},
							"name": "CSVSource"
						},
						{
							"dataset": {
								"referenceName": "AzureSynapseConcession",
								"type": "DatasetReference"
							},
							"name": "dwhdb"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSynapseConcession",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "createHash"
						},
						{
							"name": "Exists1"
						},
						{
							"name": "Lookup1"
						},
						{
							"name": "SetAttrributes"
						},
						{
							"name": "Aggregate1"
						},
						{
							"name": "CreateHashNewData"
						},
						{
							"name": "AlterRow1"
						}
					],
					"script": "source(output(\n\t\tStore_Code as integer,\n\t\tStore_Name as string,\n\t\tCOMPANY as string,\n\t\tCompartment as string,\n\t\tSubCompartment as string,\n\t\tTYPE as string,\n\t\tnick_name as string,\n\t\tprod_code as string,\n\t\tNetSold_Qty as short,\n\t\tCost as string,\n\t\tRetail_Price as string,\n\t\tUnit_Price_Sold as string,\n\t\tFinalPrice as boolean,\n\t\tCONCESSION_ID as integer,\n\t\tCONCESSION_Code as string,\n\t\tNew_Price_After_Discount as string,\n\t\tCONCESSION_Description as string,\n\t\tAmount_Discount as string,\n\t\tPercent_Discount as double,\n\t\tNetSold_Amount as string,\n\t\tTAX_RATE as double,\n\t\tTAX_AMOUNT1 as double,\n\t\tTAX_AMOUNT2 as double,\n\t\temp_code as string,\n\t\tEmp_Name as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> CSVSource\nsource(output(\n\t\tCONS_ID as integer,\n\t\tCONS_CODE as string,\n\t\tCONS_DESCRIPTION as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> dwhdb\ndwhdb derive(dimhash = sha1(CONS_CODE+ CONS_DESCRIPTION)) ~> createHash\nCreateHashNewData, createHash exists(newdatahash == dimhash,\n\tnegate:true,\n\tbroadcast: 'auto')~> Exists1\nExists1, dwhdb lookup(CONCESSION_Code == CONS_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> Lookup1\nLookup1 derive(CONS_CODE = CONCESSION_Code,\n\t\tCONS_DESCRIPTION = CONCESSION_Description,\n\t\t{_inserted_dt} = iif(isNull(CONS_ID) ,  currentTimestamp(), {_inserted_dt}),\n\t\t{_updated_dt} = currentTimestamp()) ~> SetAttrributes\nSetAttrributes aggregate(groupBy(CONS_DESCRIPTION,\n\t\tCONS_CODE,\n\t\tCONS_ID,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}),\n\tcount = count(CONS_DESCRIPTION)) ~> Aggregate1\nCSVSource derive(newdatahash = sha1(CONCESSION_Code + CONCESSION_Description)) ~> CreateHashNewData\nAggregate1 alterRow(insertIf(isNull(CONS_ID)),\n\tupdateIf(not(isNull(CONS_ID)))) ~> AlterRow1\nAlterRow1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tCONS_ID as integer,\n\t\tCONS_CODE as string,\n\t\tCONS_DESCRIPTION as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:true,\n\tupsertable:false,\n\tkeys:['CONS_CODE'],\n\tformat: 'table',\n\tstaged: true,\n\tallowCopyCommand: true,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError',\n\tmapColumn(\n\t\tCONS_DESCRIPTION,\n\t\tCONS_CODE,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowemployee')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "IntermediateCSV",
								"type": "DatasetReference"
							},
							"name": "CSVSource"
						},
						{
							"dataset": {
								"referenceName": "AzureSynapseEmployee",
								"type": "DatasetReference"
							},
							"name": "dwhdb"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSynapseEmployee",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "createHash"
						},
						{
							"name": "Exists1"
						},
						{
							"name": "Lookup1"
						},
						{
							"name": "SetAttrributes"
						},
						{
							"name": "Aggregate1"
						},
						{
							"name": "CreateHashNewData"
						},
						{
							"name": "AlterRow1"
						}
					],
					"script": "source(output(\n\t\tStore_Code as integer,\n\t\tStore_Name as string,\n\t\tCOMPANY as string,\n\t\tCompartment as string,\n\t\tSubCompartment as string,\n\t\tTYPE as string,\n\t\tnick_name as string,\n\t\tprod_code as string,\n\t\tNetSold_Qty as short,\n\t\tCost as string,\n\t\tRetail_Price as string,\n\t\tUnit_Price_Sold as string,\n\t\tFinalPrice as boolean,\n\t\tCONCESSION_ID as integer,\n\t\tCONCESSION_Code as string,\n\t\tNew_Price_After_Discount as string,\n\t\tCONCESSION_Description as string,\n\t\tAmount_Discount as string,\n\t\tPercent_Discount as double,\n\t\tNetSold_Amount as string,\n\t\tTAX_RATE as double,\n\t\tTAX_AMOUNT1 as double,\n\t\tTAX_AMOUNT2 as double,\n\t\temp_code as string,\n\t\tEmp_Name as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> CSVSource\nsource(output(\n\t\tEMP_ID as integer,\n\t\tEMP_CODE as string,\n\t\tEMP_NAME as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> dwhdb\ndwhdb derive(dimhash = sha1(EMP_CODE+EMP_NAME)) ~> createHash\nCreateHashNewData, createHash exists(newdatahash == dimhash,\n\tnegate:true,\n\tbroadcast: 'auto')~> Exists1\nExists1, dwhdb lookup(CSVSource@emp_code == dwhdb@EMP_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> Lookup1\nLookup1 derive(EMP_CODE = CSVSource@emp_code,\n\t\tEMP_NAME = CSVSource@Emp_Name,\n\t\t{_inserted_dt} = iif(isNull(EMP_ID) ,  currentTimestamp(), {_inserted_dt}),\n\t\t{_updated_dt} = currentTimestamp()) ~> SetAttrributes\nSetAttrributes aggregate(groupBy(SetAttrributes@EMP_NAME,\n\t\tSetAttrributes@EMP_CODE,\n\t\tEMP_ID,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}),\n\tcount = count(SetAttrributes@EMP_NAME)) ~> Aggregate1\nCSVSource derive(newdatahash = sha1(emp_code + Emp_Name)) ~> CreateHashNewData\nAggregate1 alterRow(insertIf(isNull(EMP_ID)),\n\tupdateIf(not(isNull(EMP_ID)))) ~> AlterRow1\nAlterRow1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tEMP_ID as integer,\n\t\tEMP_CODE as string,\n\t\tEMP_NAME as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:true,\n\tupsertable:false,\n\tkeys:['EMP_CODE'],\n\tformat: 'table',\n\tstaged: true,\n\tallowCopyCommand: true,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError',\n\tmapColumn(\n\t\tEMP_CODE = EMP_NAME,\n\t\tEMP_NAME = EMP_CODE,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowprod')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "IntermediateCSV",
								"type": "DatasetReference"
							},
							"name": "CSVSource"
						},
						{
							"dataset": {
								"referenceName": "AzureSynapseAnalyticsProd",
								"type": "DatasetReference"
							},
							"name": "dwhdb"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlProduct",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "createHash"
						},
						{
							"name": "Exists1"
						},
						{
							"name": "Lookup1"
						},
						{
							"name": "SetAttrributes"
						},
						{
							"name": "Aggregate1"
						},
						{
							"name": "CreateHashNewData"
						},
						{
							"name": "AlterRow1"
						}
					],
					"script": "source(output(\n\t\tStore_Code as integer,\n\t\tStore_Name as string,\n\t\tCOMPANY as string,\n\t\tCompartment as string,\n\t\tSubCompartment as string,\n\t\tTYPE as string,\n\t\tnick_name as string,\n\t\tprod_code as string,\n\t\tNetSold_Qty as short,\n\t\tCost as string,\n\t\tRetail_Price as string,\n\t\tUnit_Price_Sold as string,\n\t\tFinalPrice as boolean,\n\t\tCONCESSION_ID as integer,\n\t\tCONCESSION_Code as string,\n\t\tNew_Price_After_Discount as string,\n\t\tCONCESSION_Description as string,\n\t\tAmount_Discount as string,\n\t\tPercent_Discount as double,\n\t\tNetSold_Amount as string,\n\t\tTAX_RATE as double,\n\t\tTAX_AMOUNT1 as double,\n\t\tTAX_AMOUNT2 as double,\n\t\temp_code as string,\n\t\tEmp_Name as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> CSVSource\nsource(output(\n\t\tPROD_ID as integer,\n\t\tPROD_TYPE as string,\n\t\tPROD_NAME as string,\n\t\tPROD_CODE as string,\n\t\tLABEL_NAME as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> dwhdb\ndwhdb derive(dimhash = sha1(PROD_NAME+ PROD_CODE)) ~> createHash\nCreateHashNewData, createHash exists(newdatahash == dimhash,\n\tnegate:true,\n\tbroadcast: 'auto')~> Exists1\nExists1, dwhdb lookup(toString(CSVSource@prod_code) == dwhdb@PROD_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> Lookup1\nLookup1 derive(PROD_CODE = CSVSource@prod_code,\n\t\tPROD_NAME = nick_name,\n\t\tPROD_TYPE = TYPE,\n\t\t{_updated_dt} = currentTimestamp(),\n\t\tLABEL_NAME = COMPANY,\n\t\t{_inserted_dt} = iif(isNull(PROD_ID) ,  currentTimestamp(), {_inserted_dt})) ~> SetAttrributes\nSetAttrributes aggregate(groupBy(PROD_ID,\n\t\tPROD_TYPE,\n\t\tPROD_NAME,\n\t\tSetAttrributes@PROD_CODE,\n\t\tLABEL_NAME,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}),\n\tcount = count(SetAttrributes@PROD_CODE)) ~> Aggregate1\nCSVSource derive(newdatahash = sha1(nick_name+ toString(prod_code))) ~> CreateHashNewData\nAggregate1 alterRow(updateIf(not(isNull(PROD_ID))),\n\tinsertIf(isNull(PROD_ID))) ~> AlterRow1\nAlterRow1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tPROD_ID as integer,\n\t\tPROD_TYPE as string,\n\t\tPROD_NAME as string,\n\t\tPROD_CODE as string,\n\t\tLABEL_NAME as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:true,\n\tupsertable:false,\n\tkeys:['PROD_NAME'],\n\tformat: 'table',\n\tstagingSchemaName: 'sales',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError',\n\tmapColumn(\n\t\tPROD_NAME,\n\t\tPROD_TYPE,\n\t\tPROD_CODE,\n\t\tLABEL_NAME,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowrestconnect')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "rest_Json",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "IntermediateCSV",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "Flatten1"
						},
						{
							"name": "DerivedColumn1"
						}
					],
					"script": "source(output(\n\t\tresult as (Amount as string, COMPANY as string, CONCESSION_Code as string, CONCESSION_Description as string, CONCESSION_ID as integer, CST as string, Compartment as string, Concession as string, Percent_Reduce as double, Price as string, Price_Reduced as string, Quantity as short, SALE_TYPE as string, Shop_Code as string, Shop_Name as string, SubCompartment as string, TAXES1 as double, TAXES2 as double, TAX_SLAB as double, TRANSDATE as long, TRANSNUM as short, TRANSTIME as integer, TRANSTIMESTR as integer, TYPE as string, Unit_Price as string, emp_Name as string, emp_code as string, nick_name as string, prod_code as string)[]\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tdocumentForm: 'singleDocument') ~> source1\nsource1 foldDown(unroll(result),\n\tmapColumn(\n\t\tresult\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Flatten1\nFlatten1 derive(Shop_Code = result.Shop_Code,\n\t\tShop_Name = result.Shop_Name,\n\t\tCOMPANY = result.COMPANY,\n\t\tCompartment = result.Compartment,\n\t\tSubCompartment = result.SubCompartment,\n\t\tTYPE = result.TYPE,\n\t\tnick_name = result.nick_name,\n\t\tprod_code = result.prod_code,\n\t\tQuantity = result.Quantity,\n\t\tCST = result.CST,\n\t\tPrice = result.Price,\n\t\tUnit_Price = result.Unit_Price,\n\t\tPriceOverride = 0,\n\t\tCONCESSION_ID = result.CONCESSION_ID,\n\t\tCONCESSION_Code = result.CONCESSION_Code,\n\t\tPrice_Reduced = result.Price_Reduced,\n\t\tCONCESSION_Description = result.CONCESSION_Description,\n\t\tConcession = result.Concession,\n\t\tPercent_Reduce = result.Percent_Reduce,\n\t\tAmount = result.Amount,\n\t\tTAX_SLAB = result.TAX_SLAB,\n\t\tTAXES1 = result.TAXES1,\n\t\tTAXES2 = result.TAXES2,\n\t\temp_code = result.emp_Name,\n\t\tEmp_Name = result.emp_Name,\n\t\tTRANSDATE = result.TRANSDATE,\n\t\tTRANSTIME = result.TRANSTIME,\n\t\tTRANSNUM = result.TRANSNUM) ~> DerivedColumn1\nDerivedColumn1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tjson_value as string\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tmapColumn(\n\t\tCOMPANY,\n\t\tShop_Code,\n\t\tShop_Name,\n\t\tCompartment,\n\t\tSubCompartment,\n\t\tTYPE,\n\t\tnick_name,\n\t\tprod_code,\n\t\tquantity = Quantity,\n\t\tCST,\n\t\tPrice,\n\t\tUnit_Price,\n\t\tCONCESSION_ID,\n\t\tCONCESSION_Code,\n\t\tPrice_Reduced,\n\t\tCONCESSION_Description,\n\t\tConcession,\n\t\tPercent_Reduce,\n\t\tAmount,\n\t\tTAX_SLAB,\n\t\tTAXES1,\n\t\tTAXES2,\n\t\temp_code,\n\t\tEmp_Name,\n\t\tTRANSDATE,\n\t\tTRANSTIME,\n\t\tTRANSNUM\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowsales')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "IntermediateCSV",
								"type": "DatasetReference"
							},
							"name": "CSVSource"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlShop",
								"type": "DatasetReference"
							},
							"name": "ShopDim"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlEmployee",
								"type": "DatasetReference"
							},
							"name": "EmployeeDim"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlProduct",
								"type": "DatasetReference"
							},
							"name": "ProductDim"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlGroup",
								"type": "DatasetReference"
							},
							"name": "GroupDim"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlConcesssion",
								"type": "DatasetReference"
							},
							"name": "ConcessionDim"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "SalesBlob",
								"type": "DatasetReference"
							},
							"name": "sinksalesblob"
						}
					],
					"transformations": [
						{
							"name": "LookupShop"
						},
						{
							"name": "SetAttrributes"
						},
						{
							"name": "LookupEmployee"
						},
						{
							"name": "LookupProduct"
						},
						{
							"name": "LookupGroup"
						},
						{
							"name": "LookupConcession"
						}
					],
					"script": "source(output(\n\t\tCOMPANY as string,\n\t\tShop_Code as integer,\n\t\tShop_Name as string,\n\t\tCompartment as string,\n\t\tSubCompartment as string,\n\t\tTYPE as string,\n\t\tnick_name as string,\n\t\tprod_code as string,\n\t\tquantity as short,\n\t\tCST as string,\n\t\tPrice as string,\n\t\tUnit_Price as string,\n\t\tCONCESSION_ID as integer,\n\t\tCONCESSION_Code as string,\n\t\tPrice_Reduced as string,\n\t\tCONCESSION_Description as string,\n\t\tConcession as string,\n\t\tPercent_Reduce as double,\n\t\tAmount as string,\n\t\tTAX_SLAB as double,\n\t\tTAXES1 as double,\n\t\tTAXES2 as double,\n\t\temp_code as string,\n\t\tEmp_Name as string,\n\t\tTRANSDATE as long,\n\t\tTRANSTIME as integer,\n\t\tTRANSNUM as short\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> CSVSource\nsource(output(\n\t\tPOS_ID as integer,\n\t\tPOS_CODE as string,\n\t\tPOS_LABEL as string,\n\t\tDISTRICT as string,\n\t\tBLOCK as string,\n\t\tREGION as string,\n\t\tTIER as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> ShopDim\nsource(output(\n\t\tEMP_ID as integer,\n\t\tEMP_CODE as string,\n\t\tEMP_NAME as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> EmployeeDim\nsource(output(\n\t\tPROD_ID as integer,\n\t\tPROD_TYPE as string,\n\t\tPROD_NAME as string,\n\t\tPROD_CODE as string,\n\t\tLABEL_NAME as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> ProductDim\nsource(output(\n\t\tGRP_ID as integer,\n\t\tGRP_NAME as string,\n\t\tSECTION as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> GroupDim\nsource(output(\n\t\tCONS_ID as integer,\n\t\tCONS_CODE as string,\n\t\tCONS_DESCRIPTION as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> ConcessionDim\nCSVSource, ShopDim lookup(toString(Shop_Code) == POS_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> LookupShop\nLookupConcession derive(POS_ID = POS_ID,\n\t\tEMP_ID = EMP_ID,\n\t\t{_inserted_dt} = currentTimestamp(),\n\t\tCONCESSION_ID = CONS_ID,\n\t\tGRP_ID = GRP_ID,\n\t\tPROD_ID = PROD_ID,\n\t\tQuantity = quantity,\n\t\tCST = CST,\n\t\tUnit_Price = Unit_Price,\n\t\tPrice = Price,\n\t\tAmount = Amount,\n\t\tTRANSDATETIME = toTimestamp(TRANSDATE),\n\t\tTRANSTIME = TRANSTIME,\n\t\tTRANSNUM = TRANSNUM,\n\t\tTAXES1 = TAXES1,\n\t\tTAXES2 = TAXES2,\n\t\tTAX_SLAB = TAX_SLAB) ~> SetAttrributes\nLookupShop, EmployeeDim lookup(CSVSource@emp_code == EmployeeDim@EMP_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> LookupEmployee\nLookupEmployee, ProductDim lookup(CSVSource@prod_code == ProductDim@PROD_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> LookupProduct\nLookupProduct, GroupDim lookup(Compartment == GRP_NAME,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> LookupGroup\nLookupGroup, ConcessionDim lookup(CONCESSION_Code == CONS_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> LookupConcession\nSetAttrributes sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:[(concat(concat('sales-',concat(concat(concat(concat (toString(dayOfMonth(  currentUTC('GMT'))) , '-' ),  toString(month(currentUTC('GMT')))), '-'), toString( year(currentUTC('GMT'))))), '.csv'))],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tmapColumn(\n\t\tEMP_ID,\n\t\t{_inserted_dt},\n\t\tCONS_ID = CONCESSION_ID,\n\t\tGRP_ID,\n\t\tPROD_ID,\n\t\tQuantity,\n\t\tCost = CST,\n\t\tUnit_Price,\n\t\tPrice,\n\t\tAmount,\n\t\tTRANSDATETIME,\n\t\tTRANSTIME,\n\t\tTRANSNUM,\n\t\tTAXES1,\n\t\tTAXES2,\n\t\tTAX_SLAB,\n\t\tPOS_ID\n\t),\n\tpartitionBy('hash', 1)) ~> sinksalesblob"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowstore')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "IntermediateCSV",
								"type": "DatasetReference"
							},
							"name": "CSVSource"
						},
						{
							"dataset": {
								"referenceName": "AzureSynapseAnalyticsShop",
								"type": "DatasetReference"
							},
							"name": "dwhdb"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSynapseAnalyticsShop",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "createHash"
						},
						{
							"name": "Exists1"
						},
						{
							"name": "Lookup1"
						},
						{
							"name": "SetAttrributes"
						},
						{
							"name": "Aggregate1"
						},
						{
							"name": "CreateHashNewData"
						},
						{
							"name": "AlterRow1"
						}
					],
					"script": "source(output(\n\t\tCOMPANY as string,\n\t\tShop_Code as integer,\n\t\tShop_Name as string,\n\t\tCompartment as string,\n\t\tSubCompartment as string,\n\t\tTYPE as string,\n\t\tnick_name as string,\n\t\tprod_code as string,\n\t\tquantity as short,\n\t\tCST as string,\n\t\tPrice as string,\n\t\tUnit_Price as string,\n\t\tCONCESSION_ID as integer,\n\t\tCONCESSION_Code as string,\n\t\tPrice_Reduced as string,\n\t\tCONCESSION_Description as string,\n\t\tConcession as string,\n\t\tPercent_Reduce as double,\n\t\tAmount as string,\n\t\tTAX_SLAB as double,\n\t\tTAXES1 as double,\n\t\tTAXES2 as double,\n\t\temp_code as string,\n\t\tEmp_Name as string,\n\t\tTRANSDATE as long,\n\t\tTRANSTIME as integer,\n\t\tTRANSNUM as short\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> CSVSource\nsource(output(\n\t\tPOS_ID as integer,\n\t\tPOS_CODE as string,\n\t\tPOS_LABEL as string,\n\t\tDISTRICT as string,\n\t\tBLOCK as string,\n\t\tREGION as string,\n\t\tTIER as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> dwhdb\ndwhdb derive(dimhash = sha1(POS_CODE+ POS_LABEL)) ~> createHash\nCreateHashNewData, createHash exists(newdatahash == dimhash,\n\tnegate:true,\n\tbroadcast: 'auto')~> Exists1\nExists1, dwhdb lookup(toString(Shop_Code) == POS_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> Lookup1\nLookup1 derive(POS_LABEL = Shop_Name,\n\t\tPOS_CODE = Shop_Code,\n\t\t{_inserted_dt} = iif(isNull(POS_ID) ,  currentTimestamp(), {_inserted_dt}),\n\t\t{_updated_dt} = currentTimestamp()) ~> SetAttrributes\nSetAttrributes aggregate(groupBy(POS_CODE,\n\t\tPOS_LABEL,\n\t\tPOS_ID,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}),\n\tcount = count(POS_CODE)) ~> Aggregate1\nCSVSource derive(newdatahash = sha1(toString(Shop_Code) + Shop_Name)) ~> CreateHashNewData\nAggregate1 alterRow(insertIf(isNull(POS_ID)),\n\tupdateIf(not(isNull(POS_ID)))) ~> AlterRow1\nAlterRow1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tPOS_ID as integer,\n\t\tPOS_CODE as string,\n\t\tPOS_LABEL as string,\n\t\tDISTRICT as string,\n\t\tBLOCK as string,\n\t\tREGION as string,\n\t\tTIER as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\tformat: 'table',\n\tstaged: true,\n\tallowCopyCommand: true,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError',\n\tmapColumn(\n\t\tPOS_CODE,\n\t\tPOS_LABEL,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline_load_dim')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow Compartment",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflowcompartment",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"CSVSource": {},
									"dwhdb": {},
									"sink1": {}
								}
							},
							"staging": {
								"linkedService": {
									"referenceName": "AzureBlobStorage1",
									"type": "LinkedServiceReference"
								},
								"folderPath": "tmp"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "Data flow Concession",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Data flow Compartment",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflowconcession",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"CSVSource": {},
									"dwhdb": {},
									"sink1": {}
								}
							},
							"staging": {
								"linkedService": {
									"referenceName": "AzureBlobStorage1",
									"type": "LinkedServiceReference"
								},
								"folderPath": "tmp"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "Data flow Shop",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Data flow Concession",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflowstore",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"CSVSource": {},
									"dwhdb": {},
									"sink1": {}
								}
							},
							"staging": {
								"linkedService": {
									"referenceName": "AzureBlobStorage1",
									"type": "LinkedServiceReference"
								},
								"folderPath": "tmp"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "Data flow Product",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Data flow Shop",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflowprod",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"CSVSource": {},
									"dwhdb": {},
									"sink1": {}
								}
							},
							"staging": {
								"folderPath": "tmp"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"annotations": [],
				"lastPublishTime": "2021-06-23T14:17:01Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflowcompartment')]",
				"[concat(variables('factoryId'), '/dataflows/dataflowconcession')]",
				"[concat(variables('factoryId'), '/dataflows/dataflowstore')]",
				"[concat(variables('factoryId'), '/dataflows/dataflowprod')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline_load_fact')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow3",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflowsales",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"CSVSource": {},
									"ShopDim": {},
									"EmployeeDim": {},
									"ProductDim": {},
									"GroupDim": {},
									"ConcessionDim": {},
									"sinksalesblob": {}
								}
							},
							"staging": {
								"folderPath": "tmp"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"annotations": [],
				"lastPublishTime": "2021-06-23T14:17:01Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflowsales')]"
			]
		}
	]
}