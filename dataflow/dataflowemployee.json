{
	"name": "dataflowemployee",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "IntermediateCSV",
						"type": "DatasetReference"
					},
					"name": "CSVSource"
				},
				{
					"dataset": {
						"referenceName": "AzureSynapseEmployee",
						"type": "DatasetReference"
					},
					"name": "dwhdb"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "AzureSynapseEmployee",
						"type": "DatasetReference"
					},
					"name": "sink1"
				}
			],
			"transformations": [
				{
					"name": "createHash"
				},
				{
					"name": "Exists1"
				},
				{
					"name": "Lookup1"
				},
				{
					"name": "SetAttrributes"
				},
				{
					"name": "Aggregate1"
				},
				{
					"name": "CreateHashNewData"
				},
				{
					"name": "AlterRow1"
				}
			],
			"script": "source(output(\n\t\tStore_Code as integer,\n\t\tStore_Name as string,\n\t\tCOMPANY as string,\n\t\tCompartment as string,\n\t\tSubCompartment as string,\n\t\tTYPE as string,\n\t\tnick_name as string,\n\t\tprod_code as string,\n\t\tNetSold_Qty as short,\n\t\tCost as string,\n\t\tRetail_Price as string,\n\t\tUnit_Price_Sold as string,\n\t\tFinalPrice as boolean,\n\t\tCONCESSION_ID as integer,\n\t\tCONCESSION_Code as string,\n\t\tNew_Price_After_Discount as string,\n\t\tCONCESSION_Description as string,\n\t\tAmount_Discount as string,\n\t\tPercent_Discount as double,\n\t\tNetSold_Amount as string,\n\t\tTAX_RATE as double,\n\t\tTAX_AMOUNT1 as double,\n\t\tTAX_AMOUNT2 as double,\n\t\temp_code as string,\n\t\tEmp_Name as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> CSVSource\nsource(output(\n\t\tEMP_ID as integer,\n\t\tEMP_CODE as string,\n\t\tEMP_NAME as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> dwhdb\ndwhdb derive(dimhash = sha1(EMP_CODE+EMP_NAME)) ~> createHash\nCreateHashNewData, createHash exists(newdatahash == dimhash,\n\tnegate:true,\n\tbroadcast: 'auto')~> Exists1\nExists1, dwhdb lookup(CSVSource@emp_code == dwhdb@EMP_CODE,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> Lookup1\nLookup1 derive(EMP_CODE = CSVSource@emp_code,\n\t\tEMP_NAME = CSVSource@Emp_Name,\n\t\t{_inserted_dt} = iif(isNull(EMP_ID) ,  currentTimestamp(), {_inserted_dt}),\n\t\t{_updated_dt} = currentTimestamp()) ~> SetAttrributes\nSetAttrributes aggregate(groupBy(SetAttrributes@EMP_NAME,\n\t\tSetAttrributes@EMP_CODE,\n\t\tEMP_ID,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}),\n\tcount = count(SetAttrributes@EMP_NAME)) ~> Aggregate1\nCSVSource derive(newdatahash = sha1(emp_code + Emp_Name)) ~> CreateHashNewData\nAggregate1 alterRow(insertIf(isNull(EMP_ID)),\n\tupdateIf(not(isNull(EMP_ID)))) ~> AlterRow1\nAlterRow1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tEMP_ID as integer,\n\t\tEMP_CODE as string,\n\t\tEMP_NAME as string,\n\t\t{_inserted_dt} as timestamp,\n\t\t{_updated_dt} as timestamp\n\t),\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:true,\n\tupsertable:false,\n\tkeys:['EMP_CODE'],\n\tformat: 'table',\n\tstaged: true,\n\tallowCopyCommand: true,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError',\n\tmapColumn(\n\t\tEMP_CODE = EMP_NAME,\n\t\tEMP_NAME = EMP_CODE,\n\t\t{_inserted_dt},\n\t\t{_updated_dt}\n\t)) ~> sink1"
		}
	}
}